{"cells":[{"cell_type":"code","source":["lst=[]\nfor i in range(10000):\n  lst.append([str(i),\"name\"+str(i)])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["in_data=spark.sparkContext.parallelize(lst)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["in_df=spark.createDataFrame(in_data,[\"id\",\"name\"])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["in_df.rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: 8</div>"]}}],"execution_count":4},{"cell_type":"code","source":["in_df.coalesce(1).write.mode(\"overwrite\").saveAsTable(\"unbucket_demo1\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["in_df.coalesce(1).write.bucketBy(4,\"id\").sortBy(\"id\").mode(\"overwrite\").saveAsTable(\"bucket_demo1\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["df_read1=spark.table(\"unbucket_demo1\")\ndf_read1.where(\"id='1000'\").explain()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Physical Plan ==\n*(1) Project [id#1275, name#1276]\n+- *(1) Filter (isnotnull(id#1275) AND (id#1275 = 1000))\n   +- *(1) ColumnarToRow\n      +- FileScan parquet default.unbucket_demo1[id#1275,name#1276] Batched: true, DataFilters: [isnotnull(id#1275), (id#1275 = 1000)], Format: Parquet, Location: InMemoryFileIndex[dbfs:/user/hive/warehouse/unbucket_demo1], PartitionFilters: [], PushedFilters: [IsNotNull(id), EqualTo(id,1000)], ReadSchema: struct&lt;id:string,name:string&gt;\n\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["df_read=spark.table(\"bucket_demo1\")\ndf_read.where(\"id='1000'\").explain()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Physical Plan ==\n*(1) Project [id#1288, name#1289]\n+- *(1) Filter (isnotnull(id#1288) AND (id#1288 = 1000))\n   +- *(1) ColumnarToRow\n      +- FileScan parquet default.bucket_demo1[id#1288,name#1289] Batched: true, DataFilters: [isnotnull(id#1288), (id#1288 = 1000)], Format: Parquet, Location: InMemoryFileIndex[dbfs:/user/hive/warehouse/bucket_demo1], PartitionFilters: [], PushedFilters: [IsNotNull(id), EqualTo(id,1000)], ReadSchema: struct&lt;id:string,name:string&gt;, SelectedBucketsCount: 1 out of 4\n\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["spark.sql(\"Describe Extended bucket_demo1\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+-------+\n            col_name|           data_type|comment|\n+--------------------+--------------------+-------+\n                  id|              string|   null|\n                name|              string|   null|\n                    |                    |       |\n# Detailed Table ...|                    |       |\n            Database|             default|       |\n               Table|        bucket_demo1|       |\n               Owner|                root|       |\n        Created Time|Sat Jul 25 08:21:...|       |\n         Last Access|             UNKNOWN|       |\n          Created By|         Spark 3.0.0|       |\n                Type|             MANAGED|       |\n            Provider|             parquet|       |\n         Num Buckets|                   4|       |\n      Bucket Columns|              [`id`]|       |\n        Sort Columns|              [`id`]|       |\n            Location|dbfs:/user/hive/w...|       |\n       Serde Library|org.apache.hadoop...|       |\n         InputFormat|org.apache.hadoop...|       |\n        OutputFormat|org.apache.hadoop...|       |\n+--------------------+--------------------+-------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"bucketing","notebookId":3462888184506980},"nbformat":4,"nbformat_minor":0}
